{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AVWsEDSqyxLI"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20612\\3146241529.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/gdrive\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings \n",
    "import cv2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35W-nFLMc0aF"
   },
   "source": [
    "## 0. 목차 기준 Titanic Data EDA, Titanic Survival Modeling, Cross Validation 코드를 전부 필사하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwpoSl9q7jDf"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/titanic.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESKv0a9_ydeB"
   },
   "outputs": [],
   "source": [
    "titanic.shape #데이터 891개, 컬럼 12개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmBklXzhydYe"
   },
   "outputs": [],
   "source": [
    "titanic.info() #Name, Sex, Ticket, Cabin, Embarked는 문자형으로 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idO7_wbeyzsG"
   },
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q56slxuy2Bv"
   },
   "outputs": [],
   "source": [
    "#결측치 확인\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4qCEXQGy4tm"
   },
   "outputs": [],
   "source": [
    "#Age, Cabin, Embarked에서 결측치가 발견되었는데 어떻게 처리할까?\n",
    "#Age는 평균으로 처리\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y8qozyDzE29"
   },
   "outputs": [],
   "source": [
    "#cabin은 결측치가 거의 대부분인데 필요할까? 이 피처는 쓰지 않는게 좋겠음\n",
    "titanic = titanic.drop([\"Cabin\"], axis = 1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pLEN8XKzONQ"
   },
   "outputs": [],
   "source": [
    "#Embarked는 어디에서 승선했는지의 여부인데 categorical variables이므로 최빈값으로 대체\n",
    "#결측치가 2개뿐이므로 처리방식은 그다지 중요하지 않을듯\n",
    "titanic[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whszxxuozd1i"
   },
   "outputs": [],
   "source": [
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(titanic[\"Embarked\"].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVXt2eW2zb7Z"
   },
   "outputs": [],
   "source": [
    "titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YaAkRrzzv4T"
   },
   "outputs": [],
   "source": [
    "#target 접근 : 얼마나 많은 사람들이 살아남았는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwKj2mqAzzpC"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize = (16, 5)) #빈 캔버스 생성\n",
    "plt.pie(titanic[\"Survived\"].value_counts(), explode = [0.01, 0.01], labels = [\"No\", \"Yes\"], autopct = \"%.2f\")\n",
    "#생존자의 수를 바탕으로 파이플롯 작성. explode는 각 파이들이 얼마나 중점으로부터 떨어질지를 결정. labels는 각 파이의 이름을 의미. autopct는 자동으로 퍼센트를 표기하겠다는 의미.\n",
    "plt.title(\"Pie plot of the people survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUXh31Az0UJz"
   },
   "outputs": [],
   "source": [
    "#성별과 생존의 상관관계 분석\n",
    "titanic.groupby(by = [\"Sex\", \"Survived\"])[\"Survived\"].count()\n",
    "#남성이 여성보다 많이 죽은 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juPXA3Hp0fAh"
   },
   "outputs": [],
   "source": [
    "#Sex, Survived모두 categorical variables이기 때문에 catplot이 적절함\n",
    "sns.catplot(x = \"Survived\", kind = \"count\", hue = \"Sex\", data = titanic)\n",
    "plt.title(\"Sex-Survival?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxCSt2qm0vRd"
   },
   "outputs": [],
   "source": [
    "#티켓 클래스와 생존간의 상관관계 분석\n",
    "#티켓 클래스는 categorical 변수 중에서도 순서형 변수 (ordinal variable) - 그 숫자의 순위가 의미를 갖고 있음. 1은 최우등석, 2는 우등석, 3은 일반석\n",
    "sns.barplot(x = titanic[\"Pclass\"].value_counts().index, y = titanic[\"Pclass\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AC6fnVY1F8U"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x = \"Pclass\", kind = \"count\", hue = \"Survived\", data = titanic)\n",
    "#아무래도 1등석에 탄 사람들이 생존 확률이 높았음 - 구조 확률이 더 높았을 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hjLE5_51RuE"
   },
   "outputs": [],
   "source": [
    "#feature Engineering\n",
    "#sibsp, parch는 각각 친척/배우자의 수와 부모님 수를 의미함, 이를 합쳐서 family_size라는 변수로 만들어보자\n",
    "#이와 동시에 sibsp+parch인 총 동승 가족의 수가 0명인 사람에게 alone이라는 변수명을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faZZDUKI1hVt"
   },
   "outputs": [],
   "source": [
    "titanic['Family_Size'] = 0 #Family_Size라는 열 생성 및 0으로 초기화\n",
    "titanic['Family_Size'] = titanic['Parch'] + titanic['SibSp'] #가족 수 계산\n",
    "titanic['Alone'] = 0 #Alone이라는 이진분류용 열 생성 및 0으로 초기화\n",
    "titanic.loc[titanic[\"Family_Size\"] == 0, \"Alone\"] = 1 #family_size가 0인 사람은 1로 라벨링, 나머지는 여전히 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDJ-O1Oj1_tG"
   },
   "outputs": [],
   "source": [
    "#Name, PassengerID, Ticket은 중요하지 않은 변수 - 생존분석에 어떠한 도움도 주지 않는다는 것을 직관적으로 이해할 수 있음.\n",
    "titanic = titanic.drop([\"Name\", \"PassengerId\", \"Ticket\"], axis = 1)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIwnlFo1MOX4"
   },
   "outputs": [],
   "source": [
    "#Sex, Embarked 변수는 아직 categorical variable 상태이므로 인코딩 - Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_sex = LabelEncoder()\n",
    "le_sex.fit(titanic[\"Sex\"])\n",
    "titanic[\"Sex\"] = le_sex.transform(titanic[\"Sex\"])\n",
    "titanic.head()\n",
    "#Male = 1, Female = 0으로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEBgSNjYMjvU"
   },
   "outputs": [],
   "source": [
    "le_embarked = LabelEncoder()\n",
    "le_embarked.fit(titanic[\"Embarked\"])\n",
    "titanic[\"Embarked\"] = le_embarked.transform(titanic[\"Embarked\"])\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsZI3P6CMuwC"
   },
   "outputs": [],
   "source": [
    "#titanic Survival Modeling\n",
    "#필요 라이브러리 임포트\n",
    "#모델\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from xgboost import XGBClassifier #XGBoost\n",
    "import lightgbm as lgb #LightGBM\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypRZPu4DNKrs"
   },
   "outputs": [],
   "source": [
    "#기타\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1WCgSWpNiPo"
   },
   "outputs": [],
   "source": [
    "X = titanic.drop([\"Survived\"], axis = 1)\n",
    "y = titanic[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#712개의 데이터가 training, 179개 데이터가 test에서 쓰임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFMe0c5aN1yV"
   },
   "outputs": [],
   "source": [
    "#어떤 모델이든 그 성능을 여러 지표로 평가해 보여주는 함수를 제작\n",
    "def evaluate_metrics(model, X_test, y_test):\n",
    "  y_hat = model.predict(X_test)\n",
    "  print(\"Confusion matrix: \", confusion_matrix(y_test, y_hat), \"\\n\")\n",
    "  print(\"Accuracy: \", accuracy_score(y_test, y_hat), \"\\n\")\n",
    "  print(\"Precision: \", precision_score(y_test, y_hat), \"Recall: \", recall_score(y_test, y_hat), \"\\n\")\n",
    "  print(\"F1 score: \", f1_score(y_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62tZwm6GOTF6"
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "Log_R = LogisticRegression()\n",
    "Log_R.fit(X_train, y_train)\n",
    "evaluate_metrics(Log_R, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7xt1fIUOfUY"
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine 학습\n",
    "svc = svm.SVC(kernel = \"linear\", C = 0.1, gamma = 0.1)\n",
    "svc.fit(X_train, y_train)\n",
    "evaluate_metrics(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6vkXVqhOvAq"
   },
   "outputs": [],
   "source": [
    "#Decision Tree 학습\n",
    "DTclf = DecisionTreeClassifier(max_depth = 4)\n",
    "DTclf.fit(X_train, y_train)\n",
    "evaluate_metrics(DTclf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7mH-paIO5-s"
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rdk5rr_1O7R9"
   },
   "outputs": [],
   "source": [
    "#DecisionTree 다른 방식으로 시각화\n",
    "dot_data4 = tree.export_graphviz(DTclf, out_file = None,\n",
    "                                 filled = True, rounded = True,\n",
    "                                 special_characters = True, impurity = False, class_names= [\"Survived\", \"Dead\"]) #decision tree 시각화\n",
    "graph4 = graphviz.Source(dot_data4)\n",
    "graph4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tP0LSbrPX1h"
   },
   "outputs": [],
   "source": [
    "#RandomForest 학습\n",
    "RfClf = RandomForestClassifier(n_estimators = 100, max_depth = 4) #n_estimators라는 것은 숲속 나무 개수, 즉 각기 다른 tree 모델들의 개수 \n",
    "RfClf.fit(X_train, y_train)\n",
    "evaluate_metrics(RfClf, X_test, y_test) #확실히 성능이 좋음 - Decision Tree가 100개 이므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJH0QvNQPsfU"
   },
   "outputs": [],
   "source": [
    "#LightGBM 학습\n",
    "lgbClf = lgb.LGBMClassifier(num_leaves = 20)\n",
    "lgbClf.fit(X_train, y_train)\n",
    "evaluate_metrics(lgbClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em2JFL15QN3C"
   },
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array(titanic.drop([\"Survived\"], axis = 1)) #array로 설정해주는 것은 컴파일 에러를 막기 위해\n",
    "y = titanic[\"Survived\"] \n",
    "\n",
    "#n_splits는 몇개의 부분집합으로 분할할 것인지를 나타냄 - 5개로 나누었으니 학습 다섯 차례 진행\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "\n",
    "#split 개수 스텝만큼 train, test 데이터셋을 매번 분할\n",
    "for train_index, test_index in kf.split(X):\n",
    "  print(\"검증 데이터 인덱스:\", test_index)\n",
    "\n",
    "\"\"\"\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtsOlLRqRI-H"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 50)\n",
    "\n",
    "accuracy_history = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "  rfClf = RandomForestClassifier(n_estimators = 5, random_state = 0) #예시로 RandomForest모델 활용\n",
    "  rfClf.fit(X_train, y_train)\n",
    "  y_hat = rfClf.predict(X_test)\n",
    "  accuracy_history.append(accuracy_score(y_hat, y_test))\n",
    "\n",
    "print(\"평균 점수: \", np.mean(accuracy_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcV6QRpaWvfX"
   },
   "outputs": [],
   "source": [
    "#위의 과정을 조금 더 단순하게 할 수 있는 코드 - 윗 셀보다 이 코드에 더 집중하자\n",
    "from sklearn.model_selection import cross_val_score #라이브러리 임포트\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 50) #KFold 객체 생성\n",
    "\n",
    "rfClf = RandomForestClassifier(n_estimators= 5, random_state = 0) #예시로 random forest 이용\n",
    "\n",
    "cv_result = cross_val_score(rfClf, X, y, cv=kf, scoring = \"accuracy\")\n",
    "print(cv_result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onturYnLaUnT"
   },
   "source": [
    "## 1. bank.csv 를 다운로드 받고 info, describe등을 활용해 데이터의 개요를 파악하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zygbuMIS7j91"
   },
   "outputs": [],
   "source": [
    "bank = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMKQR98ZYNy-"
   },
   "outputs": [],
   "source": [
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Pey-dHNYR5l"
   },
   "outputs": [],
   "source": [
    "bank.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqV_iJvRYVMs"
   },
   "outputs": [],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig9DihRHBy2r"
   },
   "outputs": [],
   "source": [
    "bank.isnull().sum() #결측치 없는 데이터(!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyBPdgaob-BB"
   },
   "source": [
    "## 2. 데이터에 대해 각기 다른 방식으로 총 3가지 시각화를 수행하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sm3qc-2B7kVn"
   },
   "outputs": [],
   "source": [
    "#age-balance 사이의 관계 시각화\n",
    "#둘다 수치형 변수\n",
    "sns.lineplot(x = 'age', y='balance', data = bank)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BbdIRrvQd9eg"
   },
   "outputs": [],
   "source": [
    "#loan 여부에 따른 balance 분포\n",
    "plt.boxplot([bank.loc[bank[\"loan\"]==\"yes\", \"balance\"], bank.loc[bank[\"loan\"]==\"no\", \"balance\"]])\n",
    "plt.xticks([1, 2], [\"yes\", \"no\"])\n",
    "plt.show()\n",
    "#생각보다 outlier가 많음... 별로 의미 있는 분석은 아닌 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJJwPlQLe5o6"
   },
   "outputs": [],
   "source": [
    "#job에 따른 평균 나이\n",
    "df = bank.groupby(by = [\"job\"]).mean()\n",
    "plt.barh(df.index, df[\"age\"])\n",
    "plt.show()\n",
    "#은퇴한 사람은 확실히 나이가 많다. 학생은 어리다. 나머지는 다 비슷비슷하게 중년나이인듯."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw9RCO-lczih"
   },
   "source": [
    "## 3. 컬럼 간 연산을 통해 분석에 필요할 것이라고 생각하는 컬럼을 추가하고 근거를 제시하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLPpC4OJqrsN"
   },
   "outputs": [],
   "source": [
    "#default, housing, loan -> 모두 대출... 이런쪽 -> 하나로 합쳐서 표현해도 될 것 같은?\n",
    "bank[\"default\"].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyx8wfryrdG6"
   },
   "outputs": [],
   "source": [
    "bank[\"housing\"].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oc5to0P4rp2L"
   },
   "outputs": [],
   "source": [
    "bank[\"loan\"].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cE-4XvAsQ3o"
   },
   "outputs": [],
   "source": [
    "bank[\"loan_all\"] = 0\n",
    "# yes = 1, no = 0로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csVkUJwy6rII"
   },
   "outputs": [],
   "source": [
    "cond_loan = (bank[\"default\"] == 'yes') | (bank[\"housing\"] == 'yes') | (bank[\"loan\"] == 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGfDDjtvsfIF"
   },
   "outputs": [],
   "source": [
    "bank.loc[(cond_loan),\"loan_all\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBitO1Zq7HoQ"
   },
   "outputs": [],
   "source": [
    "bank.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqtHkfxGdPAb"
   },
   "source": [
    "## 4. 라벨인코딩을 통해 모든 범주형 변수를 인코딩하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9d6NHNo7lKK"
   },
   "outputs": [],
   "source": [
    "#범주형변수: job\tmarital\teducation\tdefault\thousing\tloan\tcontact\t(month)\tpoutcome\ty\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labels = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"poutcome\", \"y\"]\n",
    "for label in labels:\n",
    "  le = LabelEncoder()\n",
    "  le.fit(bank[label])\n",
    "  bank[label] = le.transform(bank[label])\n",
    "\"\"\"\n",
    "le_job = LabelEncoder()\n",
    "le_job.fit(bank[\"job\"])\n",
    "bank[\"job\"] = le_job.transform(bank[\"job\"])\n",
    "\"\"\"\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IA7q7aPHoklH"
   },
   "outputs": [],
   "source": [
    "le_marital = LabelEncoder()\n",
    "le_marital.fit(bank[\"marital\"])\n",
    "bank[\"marital\"] = le_marital.transform(bank[\"marital\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9bQfOH6pbdW"
   },
   "outputs": [],
   "source": [
    "le_education = LabelEncoder()\n",
    "le_education.fit(bank[\"education\"])\n",
    "bank[\"education\"] = le_education.transform(bank[\"education\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6LBjstq_otPE"
   },
   "outputs": [],
   "source": [
    "le_default = LabelEncoder()\n",
    "le_default.fit(bank[\"default\"])\n",
    "bank[\"default\"] = le_default.transform(bank[\"default\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nm8WlRDOo0wo"
   },
   "outputs": [],
   "source": [
    "le_housing = LabelEncoder()\n",
    "le_housing.fit(bank[\"housing\"])\n",
    "bank[\"housing\"] = le_housing.transform(bank[\"housing\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSXN0uuho5D3"
   },
   "outputs": [],
   "source": [
    "le_loan = LabelEncoder()\n",
    "le_loan.fit(bank[\"loan\"])\n",
    "bank[\"loan\"] = le_loan.transform(bank[\"loan\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tIP6mCxqpCZY"
   },
   "outputs": [],
   "source": [
    "le_contact = LabelEncoder()\n",
    "le_contact.fit(bank[\"contact\"])\n",
    "bank[\"contact\"] = le_contact.transform(bank[\"contact\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZPmrxqopJLU"
   },
   "outputs": [],
   "source": [
    "le_poutcome = LabelEncoder()\n",
    "le_poutcome.fit(bank[\"poutcome\"])\n",
    "bank[\"poutcome\"] = le_poutcome.transform(bank[\"poutcome\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9IwdzYXpSxk"
   },
   "outputs": [],
   "source": [
    "le_y = LabelEncoder()\n",
    "le_y.fit(bank[\"y\"])\n",
    "bank[\"y\"] = le_y.transform(bank[\"y\"])\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niKN_To0doal"
   },
   "source": [
    "## 5. 쓸모없는 컬럼이 있다면 제거하고 그 근거를 제시하라.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPOJvIvL7llP"
   },
   "outputs": [],
   "source": [
    "# ID -> 그냥 사람 식별용이라 무의미함 // 월, 일은 지금 날짜를 모르는 상황에서 의미 있는 값으로 바꾸기 어려움.\n",
    "bank.drop(columns = [\"ID\"], inplace=True)\n",
    "bank.drop(columns = [\"day\", \"month\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2v-9uGK7Zok"
   },
   "outputs": [],
   "source": [
    "# 위에서 하나로 합쳤던 loan 관련 세가지 컬럼 모두 제거\n",
    "bank.drop(columns = [\"default\", \"housing\", \"loan\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxcKrmTS7uCo"
   },
   "outputs": [],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR4uVD2SdzLD"
   },
   "source": [
    "## 6. train_test_split 메소드를 활용해 데이터를 학습 데이터와 검증 데이터로 나누어라. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OT55Z9me7mIF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from xgboost import XGBClassifier #XGBoost\n",
    "import lightgbm as lgb #LightGBM\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKZZDcr51Op7"
   },
   "outputs": [],
   "source": [
    "X = bank.drop([\"y\"], axis = 1)\n",
    "y = bank[\"y\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAbzLWGt1mNF"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3RPCVDXecKb"
   },
   "source": [
    "## 7. 3가지 다른 모델로 데이터를 학습한 뒤 accuracy와 F1 score 차원에서 성능을 비교하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukqDx6J71vJc"
   },
   "outputs": [],
   "source": [
    "#성능을 보여주는 함수\n",
    "def evaluate_metrics(model, X_test, y_test):\n",
    "  y_hat = model.predict(X_test)\n",
    "  print(\"Accuracy: \", accuracy_score(y_test, y_hat), \"\\n\")\n",
    "  print(\"F1 score: \", f1_score(y_test, y_hat), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8LyxFPY7nAK",
    "outputId": "67e92e48-34d9-4df2-a058-7b9f6e491d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7261072261072261 \n",
      "\n",
      "F1 score:  0.32793136320305055 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "Log_R = LogisticRegression()\n",
    "Log_R.fit(X_train, y_train)\n",
    "evaluate_metrics(Log_R, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TasuD8Aw17BD"
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine - 너무오래걸림 ㅠㅠ\n",
    "svc = svm.SVC(kernel = \"linear\", C = 0.1, gamma = 0.1)\n",
    "svc.fit(X_train, y_train)\n",
    "evaluate_metrics(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txP7NL6CjOp4"
   },
   "outputs": [],
   "source": [
    "lgbClf = lgb.LGBMClassifier(num_leaves = 20)\n",
    "lgbClf.fit(X_train, y_train)\n",
    "evaluate_metrics(lgbClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvtxRkuD9iC5"
   },
   "outputs": [],
   "source": [
    "#RandomForest 학습\n",
    "RfClf = RandomForestClassifier(n_estimators = 100, max_depth = 4)\n",
    "RfClf.fit(X_train, y_train)\n",
    "evaluate_metrics(RfClf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsQHcG8Keok7"
   },
   "source": [
    "## 8. 7번에서 가장 성능이 좋았던 모델을 Cross Validation해서 최종 accuracy와 F1 점수의 평균값을 제시하라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WF-4tQX7nmD"
   },
   "outputs": [],
   "source": [
    "#Cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array(bank.drop([\"y\"], axis = 1))\n",
    "y = bank[\"y\"] \n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvcOc1BW9x2R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score #라이브러리 임포트\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 50) #KFold 객체 생성\n",
    "\n",
    "rfClf = RandomForestClassifier(n_estimators= 5, random_state = 0) #예시로 random forest 이용\n",
    "\n",
    "cv_accuracy_result = cross_val_score(rfClf, X, y, cv=kf, scoring = \"accuracy\")\n",
    "cv_f1_result = cross_val_score(rfClf, X, y, cv=kf, scoring = \"f1\")\n",
    "print(\"accuracy mean: \", cv_accuracy_result.mean(), \"\\n\")\n",
    "print(\"f1 mean: \", cv_f1_result.mean(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyouTWp-iGHu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hJjSf6CR0hLW",
    "52RnIXgFGKhY",
    "mfCIh1ml1zio",
    "qgn8ySyMVe0o",
    "z7NxHsDsWFCd",
    "vjZ045PVPdl_",
    "C7FEyp0z3HN4",
    "65O9rvHJ3O6o",
    "OLfReYQEGYPJ",
    "ATSM5wJo4gId",
    "FBzwrSnahX4P",
    "CAcckhUOj1lU",
    "_gDI8A0pFrOB",
    "p8k3kg3DHHQO",
    "TBLj17t8RXCv",
    "vauQr9kc-W1D",
    "aKpejh9xSjHs",
    "lE1pw6ezdKMN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
